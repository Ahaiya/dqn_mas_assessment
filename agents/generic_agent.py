"""
Generic Agent Implementation
============================
ä¸‡èƒ½è¯„ä¼°ä»£ç†ã€‚
å®ƒä¸å†ç¡¬ç¼–ç è§’è‰² (Architect/Strategist)ï¼Œè€Œæ˜¯æ ¹æ®ä¼ å…¥çš„é…ç½®åŠ¨æ€æ‰®æ¼”è§’è‰²ã€‚
"""
from typing import Optional
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import Runnable

# å¼•å…¥æ–°çš„é€šç”¨ Schema
from core.schemas import AgentOutput, EvaluationSubject
from config.model_factory import get_core_model


class GenericAgent:
    def __init__(self, role_name: str, system_prompt: str, temperature: float = 0.0):
        """
        åˆå§‹åŒ–ä¸‡èƒ½ä»£ç†
        :param role_name: è§’è‰²åç§° (e.g. "Content_Expert")
        :param system_prompt: å·²ç»æ³¨å…¥äº†é‡è§„çš„å®Œæ•´ System Prompt
        :param temperature: æ¨¡åž‹æ¸©åº¦
        """
        self.role_name = role_name

        # 1. åˆå§‹åŒ–æ¨¡åž‹
        self.llm = get_core_model(temperature=temperature)

        # 2. ç»‘å®šç»“æž„åŒ–è¾“å‡º (Schema)
        # æ³¨æ„: AgentOutput çŽ°åœ¨æ˜¯é€šç”¨çš„ï¼Œrole å­—æ®µæ˜¯ str ç±»åž‹ï¼Œå¯ä»¥å…¼å®¹ä»»ä½•è§’è‰²
        self.structured_llm = self.llm.with_structured_output(AgentOutput)

        # 3. æž„å»º Prompt
        # input_data å°†å¡«å…¥ EvaluationSubject.to_markdown_context() çš„ç»“æžœ
        self.prompt = ChatPromptTemplate.from_messages([
            ("system", system_prompt),
            ("user", "ã€å¾…è¯„ä¼°å¯¹è±¡ã€‘\n{input_data}")
        ])

        # 4. ç»„è£…é“¾
        self.chain: Runnable = self.prompt | self.structured_llm

    def run(self, subject: EvaluationSubject, previous_reviews: Optional[list] = None) -> AgentOutput:
        """
        æ‰§è¡Œè¯„ä¼°
        :param subject: æ³›åŒ–çš„å¾…è¯„ä¸»ä½“ (åŽŸ StudentSubmission)
        :param previous_reviews: (å¯é€‰) ä¸Šä¸€è½®è¾©è®ºåŽ†å²
        """
        print(f"ðŸ¤– [{self.role_name}] æ­£åœ¨è¯„ä¼° {subject.subject_id} ...")

        # 1. å‡†å¤‡ä¸Šä¸‹æ–‡
        context_str = subject.to_markdown_context()

        # 2. (å¯é€‰) æ³¨å…¥è¾©è®ºåŽ†å²
        # å¦‚æžœæœ‰ previous_reviewsï¼Œæˆ‘ä»¬éœ€è¦å°†å…¶æ‹¼æŽ¥åˆ° input_data æˆ– system prompt ä¸­
        # è¿™é‡Œç®€åŒ–å¤„ç†ï¼šç›´æŽ¥æ‹¼æŽ¥åˆ°ç”¨æˆ·è¾“å…¥çš„å¼€å¤´
        if previous_reviews:
            history_text = self._format_history(previous_reviews)
            final_input = f"ã€ä¸Šä¸€è½®ä¸“å®¶ç»„æ„è§ (è¯·ä»”ç»†é˜…è¯»å¹¶åæ€)ã€‘\n{history_text}\n\n{context_str}"
        else:
            final_input = context_str

        # 3. æ‰§è¡Œè°ƒç”¨
        result = self.chain.invoke({"input_data": final_input})

        # 4. å¼ºåˆ¶ä¿®æ­£è§’è‰²å (ä¿æŒæ•°æ®ä¸€è‡´æ€§)
        if result.role != self.role_name:
            result.role = self.role_name

        return result

    def _format_history(self, reviews) -> str:
        """ç®€å•çš„åŽ†å²æ ¼å¼åŒ–"""
        text = ""
        for r in reviews:
            text += f"> {r.role}: {r.overall_score}åˆ† | {r.thought_process[:50]}...\n"
        return text