"""
ASAP Dataset Loader (Decoupled Version)
=======================================
åŠŸèƒ½ï¼š
1. ä» data/raw_submissions è¯»å– TSV æ•°æ®
2. ä» data/metadata è¯»å– JSON é…ç½® (åŸæ–‡ã€é¢˜ç›®)
3. ç»„è£… EvaluationSubject å¯¹è±¡
"""
import pandas as pd
import numpy as np
import os
import json
from typing import List, Tuple, Dict, Any
from core.schemas import EvaluationSubject, AssessmentArtifact, ArtifactType


class ASAPLoader:
    def __init__(self, tsv_path: str, metadata_path: str):
        """
        åˆå§‹åŒ–åŠ è½½å™¨
        :param tsv_path: è®­ç»ƒæ•°æ®è·¯å¾„ (.tsv)
        :param metadata_path: å…ƒæ•°æ®é…ç½®è·¯å¾„ (.json)
        """
        self.tsv_path = tsv_path
        self.metadata_path = metadata_path
        self.df = None

        # ç¼“å­˜é…ç½®æ•°æ®
        self.context_data: Dict[str, Any] = {}
        self._load_metadata()

    def _load_metadata(self):
        """åŠ è½½ JSON é…ç½®æ–‡ä»¶"""
        if not os.path.exists(self.metadata_path):
            raise FileNotFoundError(f"âŒ å…ƒæ•°æ®æ–‡ä»¶ç¼ºå¤±: {self.metadata_path}")

        with open(self.metadata_path, 'r', encoding='utf-8') as f:
            self.context_data = json.load(f)
        print(f"âœ… Metadata loaded from {os.path.basename(self.metadata_path)}")

    def load_dataset(self):
        """åŠ è½½ TSV æ•°æ®é›†"""
        if not os.path.exists(self.tsv_path):
            raise FileNotFoundError(f"âŒ æ•°æ®é›†ç¼ºå¤±: {self.tsv_path}")

        print(f"ğŸ“‚ Loading ASAP dataset from {self.tsv_path}...")
        try:
            # ASAP æ•°æ®é›†é€šå¸¸æ˜¯ ISO-8859-1 ç¼–ç 
            self.df = pd.read_csv(self.tsv_path, sep='\t', encoding='ISO-8859-1')
            # è¿‡æ»¤æ‰æ²¡æœ‰ domain1_score çš„è¡Œ
            self.df = self.df.dropna(subset=['domain1_score'])
            print(f"âœ… Loaded {len(self.df)} essays.")
        except Exception as e:
            print(f"âŒ Read Error: {e}")
            self.df = pd.DataFrame()

    def get_split_indices(self, split: str = 'train', seed: int = 42) -> List[int]:
        """è·å–åˆ‡åˆ†ç´¢å¼• (80/20 split)"""
        if self.df is None:
            self.load_dataset()

        total_size = len(self.df)
        indices = np.arange(total_size)

        np.random.seed(seed)
        np.random.shuffle(indices)

        split_point = int(total_size * 0.8)

        if split == 'train':
            return indices[:split_point]
        else:
            return indices[split_point:]

    def get_subject_by_index(self, index: int) -> Tuple[EvaluationSubject, float]:
        """
        è·å–æŒ‡å®šè¡Œå·çš„æ•°æ®ï¼Œå¹¶å°è£…ä¸ºå¯¹è±¡
        """
        if self.df is None:
            self.load_dataset()

        row = self.df.iloc[index]

        # æ³¨æ„ï¼šJSON ä¸­çš„ key éƒ½æ˜¯å­—ç¬¦ä¸²ï¼Œè€Œ DataFrame é‡Œçš„ set_id æ˜¯ int
        set_id_int = int(row['essay_set'])
        set_id_str = str(set_id_int)

        raw_score = float(row['domain1_score'])
        essay_text = str(row['essay'])
        essay_id = str(row['essay_id'])

        # 1. ä» JSON é…ç½®ä¸­è·å–å‚æ•°
        # æ»¡åˆ†èŒƒå›´
        score_ranges = self.context_data.get("score_ranges", {})
        max_score = score_ranges.get(set_id_str, 10)

        # é¢˜ç›®èƒŒæ™¯
        prompts = self.context_data.get("prompts", {})
        prompt_text = prompts.get(set_id_str, "Unknown Topic")

        # é˜…è¯»åŸæ–‡ (ä»…éƒ¨åˆ† Set æœ‰)
        source_texts = self.context_data.get("source_texts", {})
        source_text = source_texts.get(set_id_str, None)

        # 2. åˆ†æ•°å½’ä¸€åŒ– (0-5)
        norm_score = (raw_score / max_score) * 5.0
        norm_score = max(0.0, min(5.0, norm_score))

        # 3. æ„å»ºå¯¹è±¡
        subject = EvaluationSubject(
            subject_id=f"Set{set_id_int}_ID{essay_id}",
            reference_text=source_text,  # æ³¨å…¥åŸæ–‡
            metadata={
                "set_id": set_id_int,
                "raw_max_score": max_score,
                "context": prompt_text,
                "original_score": raw_score
            },
            artifacts=[
                AssessmentArtifact(
                    type=ArtifactType.TEXT_CONTENT,
                    filename=f"essay_set_{set_id_int}.txt",
                    content=essay_text,
                    description=f"Student Essay (Set {set_id_int})"
                )
            ]
        )

        return subject, norm_score